<font face="times">

# HW6 - Theory - Due March 13th (with PP5)


<b>Q1)</b> Just a preliminary exercise to warm up. Let $X$ have the following PMF.

$$
X =
\begin{cases}
-2 \qquad \text{ with probability } \qquad .10    \\\
-1 \qquad \text{ with probability } \qquad .15    \\\
0 \qquad \text{ with probability } \qquad  .50  \\\
1 \qquad \text{ with probability } \qquad .15   \\\
2 \qquad \text{ with probability } \qquad .10    \\\
\end{cases}
$$

1) Draw the PMF and CDF associated with this random variable.
2) Compute $E[X]$.

<font color="blue">

$$E[X] = -2\times 0.1 + \cdots + 2\times 0.1 = 0$$

</font>


3) Let Y = X^2 . Draw the PMF and CDF associated with this random variable.

<font color="blue">

$$
p_Y(y) =
\begin{cases}
.50  \qquad \text{ if } y = 0 \\\
.30  \qquad \text{ if } y = 1 \\\
.20  \qquad \text{ if } y = 4
\end{cases}
$$

$$
F_Y(y) =
\begin{cases}
0 \qquad \text{  if } y < 0 \\\
.50  \qquad \text{ if } 0 \leq y < 1 \\\
.80  \qquad \text{ if } 1 \leq y < 4 \\\
1  \qquad \text{ if } 4 \leq y
\end{cases}
$$

</font>

4) Compute $E[Y]$.

<font color="blue">

$$E[Y] = 0 \times 0.5 + 1\times 0.3 + 4\times 0.2 = 1.1$$

</font>

---

<b>Q2)</b> Recall that when we say $X \sim Bernoulli(p)$ we mean the following.

$$
X =
\begin{cases}
0 \qquad \text{ with probability } \qquad 1-p    \\\
1 \qquad \text{with probability } \qquad  p
\end{cases}
$$

Compute the $E[X]$.

<font color="blue">

$$E[X] = 0 \times (1-p) + 1\times p= p$$

</font>

---

<b>Q3)</b> Now suppose that we have two $Bernoulli(p)$ random variables, $X_1$ and $X_2$, both with the same PMF and in the previous question. *Using linearity*, compute the expectation of
$$Y = X_1 + X_2$$

<font color="blue">

Linearity is what makes the second equality true.

$$E[Y] = E[X_1 + X_2] = E[X_1] + E[X_2] = p + p = 2p$$

</font>


---

<b>Q4)</b> I'd like to ask you to compute the expectation of a general $Binomial(n,p)$ random variable. However, remember that the PMF with arbitrary $n$ and $p$ is kind of a mess:

$$Y\sim Binomial(n,p) \qquad \text{has PMF} \qquad p_Y(k) = {n \choose k} p^{k}(1-p)^{n-k}$$

So to find the expectation we'd have to compute

$$E[X] = 0\cdot {n \choose 0} p^{0}(1-p)^{n} +
        1\cdot {n \choose 1} p^{1}(1-p)^{n-1} + \cdots +
        n\cdot{n \choose n} p^{n}(1-p)^{n-n}$$

How can you possibly simplify that?! It turns that it's possible to grind through the algebra, as this <a href="https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/binomial-random-variables/v/expected-value-of-binomial-distribution">Khan Academy video</a> explains. But let's not do that. Instead:

1) Use what you know about Binomial random variables, linearity, and your answers to Q2 and Q3 to show, without doing any algebra, that if $Y \sim Binomial(n,p)$ then

$$E[Y] = np$$

<font color="blue">

$$E[Y] = E[X_1 + \cdots + X_n] = E[X_1] + \cdots + E[X_n] = np$$

</font>

2) [Open-ended] Explain in plain English why this formula makes sense.

<font color="blue">

If you flipped a fair coin 100 times, you'd expect the number of Heads to be roughly around 50. Moreover, if the coin was bent in such a way that the probability of Heads were $0.2$, you'd expect to see about $20 = 100 \times 0.2 = 100 \times p$ Heads. In more generality, if you flipped $n$ coins, you'd expect to see about $np$ Heads.


</font>


---

<b>Q5)</b> This problem is related to the <a href="https://en.wikipedia.org/wiki/Expected_utility_hypothesis">Expected Utility Hypothesis</a> that you might have heard of in your micro theory class (if you haven't, you can still solve this problem).

A person is considering whether or not to buy insurance against burglary for their house.

+ The house has 1000 dollars worth of stuff in it. If the house is not burgled, all the value remains intact.
+ If the house is broken in, a burglar can steal most of the valuables and leaves only 10 dollars in the house.
+ It's a risky neighborhood: the probability of a burglary is 0.1.
+ If the person pays $r$ dollars for insurance, then regardless of whether the house in burgled or not they end up with $1000 - r$ dollars (i.e., the original value of the house minus the insurance price).

We'd like to know up to how much would the person would be willing to pay for insurance.

1) We begin by modelling the value of the house without insurance like this:

$$
X_{Uninsured} =
\begin{cases}
10 \qquad \text{ with probability } \qquad  0.1    \\\
1000 \qquad \text{with probability } \qquad  0.9     \\\
\end{cases}
$$

What's the expected value of the house without insurance?


<font color="blue">

$$E[X_{Uninsured}] = 10 \times 0.1 + 1000 \times 0.9 = 901$$

</font>

2) Next, we can think about the value of the house with insurance.

$$
X_{Insured} =
\begin{cases}
1000 - r \qquad \text{with probability } 1
\end{cases}
$$

In terms of $r$, what's $E[X_{Insured}]$? (Okay, that's an easy one)


<font color="blue">

$$E[X_{Insured}] = 1\times(1000 - r) = 1000- r$$

</font>

3) What is the maximum value of $r$ such that $E[X_{Insured}] \geq E[X_{Uninsured}]$?

<font color="blue">

$$E[X_{Insured}] \geq E[X_{Uninsured}]$$
$$901 \geq 1000 - r$$

Solving for $r$, we get $r^{*} = 99$.

</font>

4) Presumably the $r$ you found above would be the maximum price anyone would be willing to pay for insurance, right? As a matter of fact, that's not what happens: in reality people are much more willing to pay for extra safety. This is called *risk aversion*, and it's a source of profit for insurance companies.

Economic theory explains this phenomenon like this. People's *utility* for value (i.e. how happy they are with the value they own) usually doesn't increase linearly with value. That is, a person with 1000 dollars is not 100 times happier than a person who has 10 dollars. Moreover, a person whose wealth increases from 10 to 11 dollars gets marginally happier than a person whose wealth increases from 1000 to 1001 dollars.

For the purposes of this exercise, let's assume that a person's utility for value increases logarithmically, like this:

$$u(x) = \ln(x)$$

(You can draw a log curve and see that it conforms to the properties I described above.)

Now, here's what I want to get at: if the value a person owns is subject to random chance, like in the setup above, then their utility will also be random! Let's create two new random variables that will describe how happy or sad the person is, in each scenario.

$$Y_{Uninsured} = u(X_{Uninsured})$$
$$Y_{Insured} = u(X_{Insured})$$

What are the PMFs of these random variables? What are $E[Y_{Uninsured}]$ and $E[Y_{Insured}]$?

<font color="blue">

PMFs:

$$
Y_{insured} = \begin{cases}
\ln(1000) \qquad \text{w.p.} \qquad 0.9 \\\
\ln(10) \qquad \text{w.p.} \qquad 0.1
\end{cases}
$$

$$
Y_{Uninsured} = \begin{cases}
\ln(1000-r) \qquad \text{w.p.} \qquad 1
\end{cases}
$$

Expectations

$$E[Y_{Uninsured}] = 0.9\times \ln(1000) + 0.1\times \ln(10)$$
$$E[Y_{Insured}] = ln(1000 - r)$$


</font>

5) What is the maximum value of $r$ such that $E[Y_{Insured}] \geq E[Y_{Uninsured}]$? (You might need a calculator)

<font color="blue">

$$E[Y_{Insured}] \geq E[Y_{Uninsured}]$$
$$\ln(1000)\times 0.9 + \ln(10)\times 0.1 \geq \ln(1000 - r)$$

Solving for $r^{*} = 1000 - 1000^{0.9}10^{0.1} \approx 369.04$


</font>


---

<b>Q6)</b> This exercise will get you thinking about empirical probabilities, and it will also prep you for the topic of *conditional expectation* that we'll see in a few weeks.

Here is a list of some of my friends, along with information about their heights and whether I met them in BC or not (BC friends are marked with a 1).

|  Name | BC  |  Height (cm) |
|---|---|---|---|---|
| Enkhmanlai Amarsaikhan  | 1  | 180  |
| Solvejg Wewel | 1  | 180  |
| Ratib Ali | 1 | 170  |
| Pierre De Leo | 1 | 190  |
| Michael Connolly | 1 | 170  |
| Dominique Brabant | 1 | 170  |
| Giselle Knowles-Carter  | 0  | 170  |
| Stefani Joanne Angelina Germanotta  | 0  | 155  |
| Hercules John  | 0  | 170  |
| Brian Hugh Warner  | 0  | 185  |
| Onika Tanya Maraj | 0  | 180  |
|  Christopher Depp II | 0  | 180  |
| Farrokh Bulsara | 0 | 170 |


Suppose I'd like to know what's the average height among all of my friends. There are two ways I could do that:

1. Take the average height of my BC friends; then take the average height of my non-BC friends; then average the two averages, remembering to give higher weights to my non-BC friends' average, since they are more numerous.
2. Don't divide my friends in groups at all, and just take the average of the seven numbers in the height column above.

Do both of these procedures give the same answer? Try it out, and if you can include an explanation (or a mathematical proof) for why or why not.

<font color="blue">

The two procedures should give the same answer. This phenomenon is often called the *Law of Iterated Expectations*  or LIE. We'll see more of that later.

</font>

---

<b>Q7)</b> [Job interview question] Vitorâ€™s phone has 1300 different songs in it, consisting of 100 albums of 13 songs each. While running on a treadmill at the Plex, he listens to 5 random songs (any more and he would collapse). Each song is equally likely and chosen independently, so repetitions may occur.

1) Let $X_1$ be a random variables that takes value 1 if the first song Vitor listens to comes from his currently favorite album (<a href="http://www.piazza.com/class_profile/get_resource/ixrnw1uhjtdyi/izngpicgppi364">*Shiny Eyed Babies*</a>, by Bent Knee), and 0 otherwise. What is the distribution of $X_1$? Give its name and its parameter(s).

<font color="blue">

This is a YES/NO event with probability $\frac{13}{1300} = \frac{1}{100}$, hence $X_1 \sim Bernoulli(\frac{1}{100})$.

</font>


2) What is the probability distribution of the number of songs that come from that particular album among the five songs Vitor listens to? Give its name and its parameter(s).

<b>Hint</b> Similarly to the first part, let $X_2$ through $X_5$ take value 1 if song number 2 through 5 come from that particular album, and take value 0 otherwise. Remember that $X_1, \cdots, X_5$ are all independent.

<font color="blue">

Let $Y$ be the number of songs from Shiny Eyed Babies. Then, in terms of the $X_i$ defined above, we have that

$$Y = X_1 + X_2 + X_3 + X_4 + X_5$$

And since this is a sum of five <u>independent</u> Bernoulli random variables with same probability of success, we have that

$$Y \sim Binomial(5, \frac{1}{100})$$


[*] Why are they independent? What would make them not be independent?
</font>



3) What is the probability that at least two songs will belong to the same album (that's *any* album, not particularly Shiny Eyed Babies)?

<b>Hint</b> Think about the complement of this event.

<font color="blue">

<b>Combinatorial solution</b>

First of all, the sample space of this experiment is $100^5$, since we have 100 possible albums for the first song, 100 for the second, 100 for the third... etc.

Next, following the hint, let's think about the event

$$A: \text{Every song comes from a different album}$$

In how many ways can we assign one different album for each song? There are 100 album possibilities for the first song, 99 for the second (since we can't repeat the first album), 98 for the third, etc. So the probability of *no* repeated albums in five songs is

$$P(A) = \frac{100\times 99\times 98 \times 97 \times 96}{100^5}$$

Finally, the number we're looking for is

$$P(A^c) = 1 - \frac{100\times 99\times 98 \times 97 \times 96}{100^5} \approx 0.0965$$


<b>Alternative solution</b>

Another way of solving this is to first figure out this *smaller problem*. Let

$A$: The five songs Vitor listens to are, in order,

| Song Order | Album |
|:-----:|:---------:|
| 1 | Shiny Eyed Babies |
| 2 | Blue Blood |
| 3 | The Bones of What You Believe |
| 4 | Subway Gawdz |
| 5 | Glenn Gould plays Bach: Goldberg Variations BWV 988 |


The probability is this *exact* event is

$$P(A) = \left(\frac{1}{100} \right)^5$$

Ok, now that we've got that down, we ask ourselves: what is the difference between this smaller problem and the original one? Well, in the original one I could choose any five-album ordering, instead of fixing that one. And how many five-album orderings are there? That's a 5-permutation of the 100 albums, so it's $\frac{100!}{95!}$. Therefore, when multiply the two we get the answer the to original problem.


<b>Yet another solution</b>

Last solution, this time using the actual songs. We can choose 5 songs out of 1300 songs in $1300^5$ ways (assuming we allow for repetition). So that's the size of our sample space, in terms of the songs.

We have 1300 options for the first song, since we're totally unconstrained. But for the next song, we must choose one out of the 1287 songs that weren't in the first album. And for the next song, we have only 1274 options... and so on.

Therefore, the probability of no songs being from the same album is

$$P(A) = \frac{1300\times 1287 \times 1274 \times 1261 \times 1248}{1300^5} \approx 0.9035$$

same as the first solution!

<b>PS</b> If you're still confused, you might want to revisit HW3Q6 and HW3Q8 (for Q8 I wrote a lengthy solution). This is a small variation on those questions.


</font>




4) [Variants of this question frequently come up in job interviews. Think hard about this one!]

Call a pair of songs a *match* if they come from the same album. For example, if the 3rd and 5th songs come from the same album, that's one match. On average, how many matches will there be in five songs?

<b>Hint</b> Here's the trick to solve this sort of question. Let $X_{12}$ take value 1 if songs 1 and 2 match, zero otherwise. Similarly, let $X_{13}$, $X_{14}$, $\cdots$, $X_{45}$ take value $1$ if their subscripts are a match, and 0 otherwise. How many of these $X_{ij}$ random variables are there? What's the probability that each one takes value 1? Are they independent? How can you use them to solve the question?


<font color="blue">

Following the hints.

First off, there are ${5 \choose 2}$ of those $X_{ij}$ variables.

Next, I'll let you convince yourself that

$$X_{ij} =
\begin{cases}
1 \qquad \text{with prob} \frac{1}{100} \\\
0 \qquad \text{with prob} \frac{99}{100}
\end{cases}
$$

Using these, we can define a random variable that summarizes the *total* number of matches:

$$Y = X_{12} + X_{13} + \cdots + X_{45}$$

Now, the $X_{ij}$ are Bernoulli, so this sum is Binomial, right?

*Wrong*, because they are not independent! For example, if we knew that $X_{12} = 1$ and $X_{13} = 1$, then necessarily it would have to be the case that $X_{23} = 1$, because if the pairs 1-2 and 1-3 come from the same album, then 2-3 must also share that album.

So how do we find the number we're looking for, namely $E[Y]$? Do we have to painstakingly derive a PMF for $Y$ first? Nope, because thankfully the linearity property of expectations allows us to simply do this:

$$\begin{align}
E[Y]
&= E[X_{12} + X_{13} + \cdots + X_{45}] \\
&= E[X_{12}] + E[X_{13}] + \cdots + E[X_{45}]
\end{align}$$
and this is regardless of the $X_{ij}$ being independent or not. The expectation operator blithely passes through the expression, gobbling up and obliterating all the randomness. We're left with this:

$$\begin{align}
E[Y]
&= E[X_{12} + X_{13} + \cdots + X_{45}] \\
&= E[X_{12}] + E[X_{13}] + \cdots + E[X_{45}] \\
&= \frac{1}{100} +  \frac{1}{100} + \cdots +  \frac{1}{100} \\
&= {5 \choose 2}\frac{1}{100} \\
\end{align}$$

Boom. Keep an eye out for job interview questions like these. They'll ask about the *expectation* of a complicated random variable $Y$, but you can easily solve it by smartly defining a bunch of (not necessarily independent) Bernoulli random variables and letting $Y$ be their sum.



</font>
